{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython import display\n",
    "import random\n",
    "import operator\n",
    "from itertools import permutations\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language_Model:\n",
    "    def __init__(self, corpus, V):\n",
    "        self.corpus = corpus\n",
    "        self.V = V\n",
    "        self.max_ngram = 3\n",
    "        self.Count_unigram = {}\n",
    "        self.Count_bigram = {}\n",
    "        self.Count_trigram = {}\n",
    "        self.P_unigram = {}\n",
    "        self.P_bigram = {}\n",
    "        self.P_trigram = {}\n",
    "        self.n_grams_counts()\n",
    "\n",
    "    def n_grams_counts(self):\n",
    "        start = []\n",
    "        end = ['</s>']\n",
    "        for i in range(max(1,self.max_ngram)):\n",
    "            start.append('<s>')\n",
    "            self.Count_unigram[str(start)] = len(self.corpus) \n",
    "        self.Count_unigram[str(end)] = len(self.corpus)\n",
    "        for tweet in self.corpus:\n",
    "            words = start+tweet+end \n",
    "            for index, word in enumerate(words[self.max_ngram-1:]):\n",
    "                context = [word]\n",
    "                if self.Count_unigram.get(str([word])) == None: \n",
    "                    self.Count_unigram[str([word])] = 0\n",
    "                self.Count_unigram[str([word])]+=1\n",
    "\n",
    "                for j in range(1,self.max_ngram): #Create n_gram\n",
    "                    context.append(words[(index + self.max_ngram -1) - j])\n",
    "                    aux_context = context.copy()\n",
    "                    aux_context.reverse()\n",
    "                    if len(aux_context) == 2:\n",
    "                        if self.Count_bigram.get(str(aux_context)) is not None: self.Count_bigram[str(aux_context)] += 1\n",
    "                        else: self.Count_bigram[str(aux_context)] = 1\n",
    "                    elif len(aux_context) == 3:\n",
    "                        if self.Count_trigram.get(str(aux_context)) is not None: self.Count_trigram[str(aux_context)] += 1\n",
    "                        else: self.Count_trigram[str(aux_context)] = 1\n",
    "                    #print(aux_context)\n",
    "    \n",
    "    def Laplace(self,cnt1, cnt2):\n",
    "        a = cnt1 + 1\n",
    "        b = cnt2 + len(self.V)\n",
    "        return a/b\n",
    "\n",
    "    def get_probability(self,words):\n",
    "        context = words[:-1]\n",
    "        size = len(words)\n",
    "        size_context = len(context)\n",
    "\n",
    "        words = str(words)\n",
    "        context = str(context)\n",
    "        cnt1 = 0\n",
    "\n",
    "        if size == 1: cnt1 = self.Count_unigram.get(words)\n",
    "        if size == 2: cnt1 = self.Count_bigram.get(words)\n",
    "        if size == 3: cnt1 = self.Count_trigram.get(words)\n",
    "        if(cnt1 == None):cnt1 = 0\n",
    "\n",
    "        cnt2 = 0\n",
    "        if size_context == 1: cnt2 = self.Count_unigram.get(context)\n",
    "        if size_context == 2: cnt2 = self.Count_bigram.get(context)\n",
    "        if (cnt2 == None):cnt2 = 0\n",
    "        \n",
    "        return self.Laplace(cnt1, cnt2)\n",
    "\n",
    "    def P_n_gram_sequence(self, sequence, n): #bigram,unigram,trigram\n",
    "        if n < 1: return\n",
    "        start = []\n",
    "        end = [\"</s>\"]\n",
    "        for i in range(max(1,n-1)):\n",
    "            start.append(\"<s>\")\n",
    "        words = start+sequence+end\n",
    "        #print(words)\n",
    "        final_p = 1\n",
    "        for i in range(len(words[n-1:])):\n",
    "            context = words[i:i+n]\n",
    "            #print(context)\n",
    "            p = self.get_probability(context)\n",
    "            final_p *= p\n",
    "\n",
    "        return final_p\n",
    "    \n",
    "    def perplexity(self,probabilities, N):\n",
    "        p = np.array(probabilities)\n",
    "        return 2**(-1/N * np.sum(np.log2(p) ))\n",
    "\n",
    "    def interpolation(self,validation, lambdas):\n",
    "        start = []\n",
    "        end = [\"</s>\"]\n",
    "        for i in range(max(1,self.max_ngram-1)):\n",
    "            start.append(\"<s>\")\n",
    "        validation = start+validation+end\n",
    "        N = len(validation)\n",
    "        size = len(validation)\n",
    "        probabilities = []\n",
    "        for idx in range(size):\n",
    "            context = []\n",
    "            p = np.zeros(3,dtype=\"float\")    \n",
    "            for j, next_word in enumerate(validation[idx:idx+3]):\n",
    "                context.append(next_word)\n",
    "                p[j] = self.get_probability(context)\n",
    "                #print(context)\n",
    "                if len(context) == 1:\n",
    "                    self.P_unigram[str(context)] = p[j] \n",
    "                elif len(context) == 2:\n",
    "                    self.P_bigram[str(context)] = p[j] \n",
    "                elif len(context) == 3:\n",
    "                    self.P_trigram[str(context)] = p[j] \n",
    "\n",
    "            final_p = p[0]*lambdas[0] + p[1]*lambdas[1] + p[2]*lambdas[2]\n",
    "            probabilities.append(final_p)\n",
    "            \n",
    "        return self.perplexity(probabilities, N)\n",
    "    \n",
    "    def tweetear(self, lambdas, stop = 50):\n",
    "        tweet = [\"<s>\",\"<s>\"]\n",
    "        while len(tweet) < stop:\n",
    "            p_next_word = []\n",
    "            words = []\n",
    "            for next_word in self.V:\n",
    "                tweet.append(next_word)\n",
    "                p = np.zeros(3,dtype=\"float\") \n",
    "                for i in range(3):\n",
    "                    context = tweet[len(tweet) - i - 1:]  \n",
    "                    p[i] = self.get_probability(context)\n",
    "                tweet.pop()   \n",
    "                p_next_word.append(p[0]*lambdas[0] + p[1]*lambdas[1] + p[2]*lambdas[2])    \n",
    "                words.append(next_word)\n",
    "            p_next_word = np.array(p_next_word,dtype = \"float\")\n",
    "            suma = np.sum(p_next_word)\n",
    "            p_next_word /= suma\n",
    "            n_word = np.random.choice(words, 1, p=p_next_word)[0]\n",
    "            tweet.append(n_word)\n",
    "        return tweet\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_from_file(path_corpus):\n",
    "    tr_tweet = []    \n",
    "    with open(path_corpus, \"r\") as f_corpus:\n",
    "        for tweet in f_corpus:\n",
    "            tr_tweet += [tweet]\n",
    "    return tr_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_vocabulary(corpus, size):\n",
    "    corpus_words = []\n",
    "    for doc in corpus:\n",
    "        corpus_words += tokenizer.tokenize(doc)\n",
    "    fdist = nltk.FreqDist(corpus_words)\n",
    "    V = [(fdist[key], key) for key in fdist]\n",
    "    V.sort() \n",
    "    V.reverse()\n",
    "    V = V[:size]\n",
    "    V = [word for count, word in V]\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(corpus, volcabulary_size):\n",
    "    # Make sure all tweets are in lowercase.\n",
    "    for i in range(len(corpus)):\n",
    "        corpus[i]= corpus[i].lower()\n",
    "    # Define vocabulary with the 500 most frequent words.\n",
    "    V = define_vocabulary(corpus, volcabulary_size)\n",
    "    # Rebuild corpus\n",
    "    new_corpus = []\n",
    "    for tweet in corpus:\n",
    "        words = tokenizer.tokenize(tweet)    \n",
    "        new_words = [\"<unk>\" if word not in V else word for word in words] # New lexicon with unknown words\n",
    "        new_corpus.append(new_words)\n",
    "    return new_corpus, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tweet = get_tweets_from_file(\"./mex_train.txt\")\n",
    "tr_tweet, V = preprocess_corpus(tr_tweet, 5000)\n",
    "V.append(\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Language_Model(tr_tweet,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"['<s>', '<s>']\": 5544,\n",
       " \"['<s>', 'lo']\": 48,\n",
       " \"['lo', 'peor']\": 12,\n",
       " \"['peor', 'de']\": 3,\n",
       " \"['de', 'todo']\": 11,\n",
       " \"['todo', 'es']\": 3,\n",
       " \"['es', 'que']\": 80,\n",
       " \"['que', 'no']\": 221,\n",
       " \"['no', 'me']\": 118,\n",
       " \"['me', 'dan']\": 13,\n",
       " \"['dan', 'por']\": 1,\n",
       " \"['por', 'un']\": 23,\n",
       " \"['un', 'tiempo']\": 3,\n",
       " \"['tiempo', 'y']\": 4,\n",
       " \"['y', 'luego']\": 20,\n",
       " \"['luego', 'vuelven']\": 1,\n",
       " \"['vuelven', 'estoy']\": 1,\n",
       " \"['estoy', 'hasta']\": 32,\n",
       " \"['hasta', 'la']\": 83,\n",
       " \"['la', 'verga']\": 419,\n",
       " \"['verga', 'de']\": 28,\n",
       " \"['de', '<unk>']\": 422,\n",
       " \"['<unk>', '</s>']\": 605,\n",
       " \"['<s>', 'a']\": 118,\n",
       " \"['a', 'la']\": 391,\n",
       " \"['la', 'vga']\": 1,\n",
       " \"['vga', 'no']\": 1,\n",
       " \"['no', 'seas']\": 18,\n",
       " \"['seas', 'mam√≥n']\": 2,\n",
       " \"['mam√≥n', '45']\": 1,\n",
       " \"['45', 'putos']\": 1,\n",
       " \"['putos', 'minutos']\": 4,\n",
       " \"['minutos', 'despu√©s']\": 1,\n",
       " \"['despu√©s', 'me']\": 5,\n",
       " \"['me', 'dices']\": 5,\n",
       " \"['dices', 'que']\": 6,\n",
       " \"['que', 'apenas']\": 1,\n",
       " \"['apenas', 'sales']\": 1,\n",
       " \"['sales', 'no']\": 1,\n",
       " \"['me', 'quer√≠as']\": 1,\n",
       " \"['quer√≠as', 'avisar']\": 1,\n",
       " \"['avisar', 'en']\": 1,\n",
       " \"['en', '3']\": 1,\n",
       " \"['3', 'horas']\": 3,\n",
       " \"['horas', '?']\": 1,\n",
       " \"['?', 'üòë']\": 1,\n",
       " \"['üòë', '</s>']\": 7,\n",
       " \"['<s>', 'considero']\": 1,\n",
       " \"['considero', 'que']\": 1,\n",
       " \"['que', 'lo']\": 29,\n",
       " \"['lo', 'm√°s']\": 14,\n",
       " \"['m√°s', '<unk>']\": 28,\n",
       " \"['<unk>', 'seria']\": 2,\n",
       " \"['seria', 'que']\": 1,\n",
       " \"['lo', '<unk>']\": 82,\n",
       " \"['<unk>', 'a']\": 372,\n",
       " \"['a', 'unos']\": 3,\n",
       " \"['unos', 'vergazos']\": 1,\n",
       " \"['vergazos', 'mi']\": 1,\n",
       " \"['mi', '<unk>']\": 74,\n",
       " \"['<unk>', '!']\": 147,\n",
       " \"['!', '<unk>']\": 57,\n",
       " \"['<unk>', 'la']\": 143,\n",
       " \"['la', 'madre']\": 194,\n",
       " \"['madre', 'a']\": 21,\n",
       " \"['a', 'ese']\": 16,\n",
       " \"['ese', 'pinchi']\": 1,\n",
       " \"['pinchi', 'joto']\": 1,\n",
       " \"['joto', '!']\": 11,\n",
       " \"['!', '</s>']\": 325,\n",
       " \"['<s>', 'el']\": 69,\n",
       " \"['el', 'marica']\": 14,\n",
       " \"['marica', 'de']\": 11,\n",
       " \"['de', 'mi']\": 88,\n",
       " \"['mi', 'ex']\": 8,\n",
       " \"['ex', 'me']\": 1,\n",
       " \"['me', 'tiene']\": 16,\n",
       " \"['tiene', '<unk>']\": 4,\n",
       " \"['<unk>', 'de']\": 470,\n",
       " \"['todo', 'as√≠']\": 1,\n",
       " \"['as√≠', 'uno']\": 1,\n",
       " \"['uno', 'no']\": 3,\n",
       " \"['no', 'puede']\": 16,\n",
       " \"['puede', 'admirar']\": 1,\n",
       " \"['admirar', 'la']\": 1,\n",
       " '[\\'la\\', \\'\"\\']': 7,\n",
       " '[\\'\"\\', \\'belleza\\']': 1,\n",
       " '[\\'belleza\\', \\'\"\\']': 1,\n",
       " '[\\'\"\\', \\'de\\']': 11,\n",
       " \"['de', 'su']\": 84,\n",
       " \"['su', '<unk>']\": 66,\n",
       " \"['<unk>', 'üòÇ']\": 17,\n",
       " \"['üòÇ', '</s>']\": 117,\n",
       " \"['<s>', 'mujer']\": 2,\n",
       " \"['mujer', '<unk>']\": 5,\n",
       " \"['<unk>', 'pinche']\": 21,\n",
       " \"['pinche', 'amlo']\": 1,\n",
       " \"['amlo', '<unk>']\": 1,\n",
       " \"['<unk>', 'esta']\": 14,\n",
       " \"['esta', 'que']\": 3,\n",
       " \"['que', 'se']\": 151,\n",
       " \"['se', 'pela']\": 1,\n",
       " \"['pela', 'la']\": 3,\n",
       " \"['la', 'loca']\": 38,\n",
       " \"['loca', '<unk>']\": 27,\n",
       " \"['<unk>', '<unk>']\": 737,\n",
       " \"['<s>', 'putos']\": 47,\n",
       " \"['putos', '.']\": 46,\n",
       " \"['.', 'no']\": 42,\n",
       " \"['no', 'tienen']\": 32,\n",
       " \"['tienen', 'madre']\": 14,\n",
       " \"['madre', '.']\": 115,\n",
       " \"['.', '<unk>']\": 158,\n",
       " \"['<unk>', '.']\": 512,\n",
       " \"['.', 'ojetes']\": 1,\n",
       " \"['ojetes', '.']\": 1,\n",
       " \"['.', 'como']\": 8,\n",
       " \"['como', 'es']\": 9,\n",
       " \"['es', 'posible']\": 3,\n",
       " \"['posible', '.']\": 1,\n",
       " \"['.', 'mejor']\": 4,\n",
       " \"['mejor', '<unk>']\": 8,\n",
       " \"['<s>', 'ustedes']\": 4,\n",
       " \"['ustedes', 'si']\": 1,\n",
       " \"['si', '<unk>']\": 40,\n",
       " \"['<unk>', 'andar']\": 1,\n",
       " \"['andar', 'de']\": 14,\n",
       " \"['<unk>', 'pero']\": 58,\n",
       " \"['pero', '<unk>']\": 22,\n",
       " \"['<unk>', 'y']\": 470,\n",
       " \"['y', 'seamos']\": 1,\n",
       " \"['seamos', 'nosotras']\": 1,\n",
       " \"['nosotras', 'porque']\": 1,\n",
       " \"['porque', 'luego']\": 1,\n",
       " \"['luego', 'luego']\": 3,\n",
       " \"['luego', 'empiezan']\": 1,\n",
       " \"['empiezan', 'a']\": 7,\n",
       " \"['a', 'mamar']\": 14,\n",
       " \"['mamar', 'hijos']\": 1,\n",
       " \"['hijos', 'de']\": 87,\n",
       " \"['de', 'la']\": 311,\n",
       " \"['la', 'chingada']\": 47,\n",
       " \"['chingada', '.']\": 10,\n",
       " \"['.', '</s>']\": 1373,\n",
       " \"['<s>', '@usuario']\": 546,\n",
       " \"['@usuario', 'jajjaja']\": 1,\n",
       " \"['jajjaja', 'te']\": 1,\n",
       " \"['te', 'digo']\": 10,\n",
       " \"['digo', 'esa']\": 1,\n",
       " \"['esa', 'madre']\": 14,\n",
       " \"['madre', 'si']\": 7,\n",
       " \"['si', 'est√°']\": 7,\n",
       " \"['est√°', 'buena']\": 2,\n",
       " \"['buena', '<unk>']\": 3,\n",
       " \"['<s>', 'odio']\": 5,\n",
       " \"['odio', 'los']\": 2,\n",
       " \"['los', 'putos']\": 175,\n",
       " \"['putos', '<unk>']\": 134,\n",
       " \"['<unk>', 'üò°']\": 5,\n",
       " \"['üò°', 'üò°']\": 36,\n",
       " \"['üò°', 'pero']\": 1,\n",
       " \"['pero', 'me']\": 19,\n",
       " \"['me', 'urge']\": 5,\n",
       " \"['urge', 'la']\": 2,\n",
       " \"['la', '<unk>']\": 301,\n",
       " \"['@usuario', 'no']\": 33,\n",
       " \"['no', 'te']\": 67,\n",
       " \"['te', '<unk>']\": 120,\n",
       " \"['<unk>', 'mi']\": 44,\n",
       " \"['mi', 'madre']\": 52,\n",
       " \"['madre', 'y']\": 46,\n",
       " \"['y', 'tu']\": 18,\n",
       " \"['tu', 'ten√≠an']\": 1,\n",
       " \"['ten√≠an', 'much√≠sima']\": 1,\n",
       " \"['much√≠sima', 'raz√≥n']\": 1,\n",
       " \"['raz√≥n', 'siempre']\": 1,\n",
       " \"['siempre', 'es']\": 2,\n",
       " \"['es', 'mejor']\": 12,\n",
       " \"['mejor', 'lo']\": 1,\n",
       " \"['lo', 'que']\": 136,\n",
       " \"['que', 'viene']\": 5,\n",
       " \"['viene', 'üíö']\": 1,\n",
       " \"['üíö', '</s>']\": 1,\n",
       " '[\\'<s>\\', \\'\"\\']': 44,\n",
       " '[\\'\"\\', \\'no\\']': 13,\n",
       " \"['me', 'importa']\": 12,\n",
       " \"['importa', 'lo']\": 13,\n",
       " \"['que', 'digan']\": 16,\n",
       " \"['digan', 'esos']\": 10,\n",
       " \"['esos', 'putos']\": 36,\n",
       " \"['putos', 'periodistas']\": 18,\n",
       " \"['periodistas', 'la']\": 8,\n",
       " \"['la', 'puta']\": 44,\n",
       " \"['puta', 'que']\": 12,\n",
       " \"['que', 'los']\": 49,\n",
       " \"['los', 'pario']\": 6,\n",
       " \"['pario', 'oh']\": 1,\n",
       " \"['oh', 'oh']\": 2,\n",
       " \"['oh', 'hay']\": 1,\n",
       " \"['hay', 'que']\": 24,\n",
       " \"['que', 'alentar']\": 4,\n",
       " \"['alentar', 'a']\": 3,\n",
       " \"['la', 'selecci√≥n']\": 14,\n",
       " '[\\'selecci√≥n\\', \\'\"\\']': 1,\n",
       " '[\\'\"\\', \\'</s>\\']': 38,\n",
       " \"['<s>', 'ok']\": 4,\n",
       " \"['ok', 'ok']\": 2,\n",
       " \"['ok', 'est√°']\": 1,\n",
       " \"['est√°', 'bien']\": 19,\n",
       " \"['bien', 'ya']\": 2,\n",
       " \"['ya', 'me']\": 76,\n",
       " \"['me', 'pas√©']\": 2,\n",
       " \"['pas√©', 'de']\": 2,\n",
       " \"['de', 'verga']\": 66,\n",
       " \"['verga', '.']\": 134,\n",
       " \"['.', '*']\": 4,\n",
       " \"['*', 'se']\": 3,\n",
       " \"['se', 'baja']\": 1,\n",
       " \"['baja', 'del']\": 1,\n",
       " \"['del', 'tren']\": 1,\n",
       " \"['tren', 'del']\": 1,\n",
       " \"['del', 'mame']\": 1,\n",
       " \"['mame', '*']\": 1,\n",
       " \"['*', '</s>']\": 8,\n",
       " \"['<s>', 'hermosas']\": 1,\n",
       " \"['hermosas', '<unk>']\": 1,\n",
       " \"['<unk>', 'üòò']\": 1,\n",
       " \"['üòò', 'üòò']\": 8,\n",
       " \"['üòò', 'con']\": 1,\n",
       " \"['con', 'ganas']\": 10,\n",
       " \"['ganas', 'de']\": 56,\n",
       " \"['de', 'mamar']\": 18,\n",
       " \"['mamar', 'ese']\": 2,\n",
       " \"['ese', 'culito']\": 4,\n",
       " \"['culito', 'hermoso']\": 1,\n",
       " \"['hermoso', '</s>']\": 1,\n",
       " \"['<s>', '<unk>']\": 391,\n",
       " \"['<unk>', 'oaxaca']\": 1,\n",
       " \"['oaxaca', '.']\": 1,\n",
       " \"['.', 'de']\": 6,\n",
       " \"['de', 'pie']\": 3,\n",
       " \"['pie', 'y']\": 1,\n",
       " \"['y', 'con']\": 15,\n",
       " \"['de', 'salir']\": 2,\n",
       " \"['salir', 'adelante']\": 3,\n",
       " \"['adelante', '.']\": 1,\n",
       " \"['.', '¬°']\": 19,\n",
       " \"['¬°', 'qu√©']\": 4,\n",
       " \"['qu√©', 'orgullo']\": 1,\n",
       " \"['orgullo', '!']\": 1,\n",
       " \"['!', 'por']\": 6,\n",
       " \"['por', 'esto']\": 1,\n",
       " \"['esto', 'te']\": 2,\n",
       " \"['te', 'amo']\": 22,\n",
       " \"['amo', 'mi']\": 2,\n",
       " \"['mi', 'm√©xico']\": 1,\n",
       " \"['m√©xico', 'por']\": 2,\n",
       " \"['por', 'tu']\": 7,\n",
       " \"['tu', 'gente']\": 3,\n",
       " \"['gente', '‚Ä¶']\": 1,\n",
       " \"['‚Ä¶', '<url>']\": 9,\n",
       " \"['<url>', '</s>']\": 54,\n",
       " \"['<s>', 'me']\": 190,\n",
       " \"['me', 'caga']\": 31,\n",
       " \"['caga', 'lo']\": 1,\n",
       " \"['lo', 'doble']\": 1,\n",
       " \"['doble', 'moral']\": 7,\n",
       " \"['moral', 'y']\": 3,\n",
       " \"['y', '<unk>']\": 243,\n",
       " \"['<unk>', 'que']\": 259,\n",
       " \"['que', 'es']\": 69,\n",
       " \"['es', 'la']\": 45,\n",
       " \"['la', 'gente']\": 46,\n",
       " \"['gente', 's√≠']\": 1,\n",
       " \"['s√≠', 'todos']\": 1,\n",
       " \"['todos', 'somos']\": 1,\n",
       " \"['somos', 'mierdas']\": 1,\n",
       " \"['mierdas', 'putas']\": 1,\n",
       " \"['putas', 'cabrones']\": 1,\n",
       " \"['cabrones', 'culeros']\": 1,\n",
       " \"['culeros', '...']\": 1,\n",
       " \"['...', '¬ø']\": 3,\n",
       " \"['¬ø', 'y']\": 13,\n",
       " \"['y', '?']\": 1,\n",
       " \"['?', '</s>']\": 203,\n",
       " \"['<s>', 'pinche']\": 37,\n",
       " \"['pinche', '<unk>']\": 42,\n",
       " \"['<unk>', 'tan']\": 14,\n",
       " \"['tan', 'pendejo']\": 2,\n",
       " \"['pendejo', '!']\": 8,\n",
       " \"['!', '!']\": 591,\n",
       " \"['!', 'ya']\": 8,\n",
       " \"['ya', '<unk>']\": 42,\n",
       " \"['que', 'estos']\": 2,\n",
       " \"['estos', 'putos']\": 11,\n",
       " \"['putos', 'son']\": 5,\n",
       " \"['son', 'ma√±osos']\": 1,\n",
       " \"['ma√±osos', '!']\": 1,\n",
       " \"['!', 'y']\": 25,\n",
       " \"['y', 'no']\": 127,\n",
       " \"['no', '<unk>']\": 119,\n",
       " \"['!', 'pendejos']\": 1,\n",
       " \"['pendejos', '!']\": 2,\n",
       " \"['!', 'as√≠']\": 3,\n",
       " \"['as√≠', 'otros']\": 1,\n",
       " \"['otros', '2']\": 2,\n",
       " \"['2', 'si']\": 1,\n",
       " \"['si', 'no']\": 70,\n",
       " \"['no', 'mejoran']\": 1,\n",
       " \"['mejoran', '!']\": 1,\n",
       " \"['@usuario', '@usuario']\": 287,\n",
       " \"['@usuario', 'y']\": 36,\n",
       " \"['y', 'si']\": 32,\n",
       " \"['si', 'este']\": 3,\n",
       " \"['este', '<unk>']\": 15,\n",
       " \"['<unk>', '#hdp']\": 2,\n",
       " \"['#hdp', '@usuario']\": 1,\n",
       " \"['@usuario', 'tuyo']\": 1,\n",
       " \"['tuyo', ';']\": 1,\n",
       " \"[';', 'se']\": 1,\n",
       " \"['se', 'queda']\": 6,\n",
       " \"['queda', 'en']\": 2,\n",
       " \"['en', '<unk>']\": 105,\n",
       " \"['<unk>', '?']\": 126,\n",
       " \"['?', 'el']\": 2,\n",
       " \"['el', 'üê∑']\": 1,\n",
       " \"['üê∑', 'd']\": 1,\n",
       " \"['d', '<unk>']\": 6,\n",
       " \"['<unk>', 'en']\": 201,\n",
       " \"['<unk>', 'estar√≠a']\": 1,\n",
       " \"['estar√≠a', 'mejor']\": 1,\n",
       " \"['mejor', 'all√°']\": 1,\n",
       " \"['all√°', '</s>']\": 1,\n",
       " \"['<s>', 'porque']\": 15,\n",
       " \"['porque', 'lo']\": 1,\n",
       " \"['lo', 'primero']\": 5,\n",
       " \"['primero', 'que']\": 6,\n",
       " \"['que', 'busco']\": 1,\n",
       " \"['busco', 'en']\": 1,\n",
       " \"['en', 'una']\": 14,\n",
       " \"['una', 'cuenta']\": 3,\n",
       " \"['cuenta', 'es']\": 1,\n",
       " \"['es', 'verificar']\": 1,\n",
       " \"['verificar', 'si']\": 1,\n",
       " \"['si', 'son']\": 10,\n",
       " \"['son', '<unk>']\": 21,\n",
       " \"['de', 'putas']\": 56,\n",
       " \"['putas', '.']\": 44,\n",
       " \"['<s>', 'se']\": 47,\n",
       " \"['se', 'llev√≥']\": 1,\n",
       " \"['llev√≥', 'mi']\": 1,\n",
       " \"['mi', 'chamarra']\": 1,\n",
       " \"['chamarra', 'mi']\": 1,\n",
       " \"['mi', 'pantal√≥n']\": 1,\n",
       " \"['pantal√≥n', 'y']\": 1,\n",
       " \"['y', 'mis']\": 6,\n",
       " \"['mis', 'tenis']\": 1,\n",
       " \"['tenis', 'basta']\": 1,\n",
       " \"['basta', 'que']\": 1,\n",
       " \"['que', 'cabrona']\": 1,\n",
       " \"['cabrona', 'es']\": 1,\n",
       " \"['es', 'me']\": 1,\n",
       " \"['tiene', 'hasta']\": 11,\n",
       " \"['verga', 'ya']\": 9,\n",
       " \"['ya', 'que']\": 15,\n",
       " \"['se', 'compre']\": 1,\n",
       " \"['compre', 'sus']\": 1,\n",
       " \"['sus', 'putas']\": 66,\n",
       " \"['putas', 'cosas']\": 1,\n",
       " \"['cosas', '<unk>']\": 3,\n",
       " \"['<s>', 'puta']\": 19,\n",
       " \"['puta', 'madre']\": 159,\n",
       " \"['madre', 'quiero']\": 2,\n",
       " \"['quiero', '<unk>']\": 12,\n",
       " \"['<unk>', 'por']\": 116,\n",
       " \"['por', 'la']\": 37,\n",
       " \"['la', 'hdp']\": 4,\n",
       " \"['hdp', 'de']\": 10,\n",
       " \"['<s>', 'no']\": 206,\n",
       " \"['no', 'hay']\": 48,\n",
       " \"['hay', 'como']\": 1,\n",
       " \"['como', 'las']\": 8,\n",
       " \"['las', '<unk>']\": 113,\n",
       " \"['madre', 'que']\": 28,\n",
       " \"['que', 'cosa']\": 2,\n",
       " \"['cosa', '<unk>']\": 2,\n",
       " \"['<s>', 'imposible']\": 2,\n",
       " \"['imposible', 'dejar']\": 1,\n",
       " \"['dejar', 'de']\": 9,\n",
       " \"['y', 'de']\": 32,\n",
       " \"['mi', 'loca']\": 2,\n",
       " \"['loca', 'pasi√≥n']\": 1,\n",
       " \"['pasi√≥n', '...']\": 1,\n",
       " \"['...', '</s>']\": 63,\n",
       " \"['<s>', 'ay']\": 16,\n",
       " \"['ay', '<unk>']\": 3,\n",
       " \"['la', 'tristeza']\": 2,\n",
       " \"['tristeza', 'invade']\": 1,\n",
       " \"['invade', 'nuestros']\": 1,\n",
       " \"['nuestros', 'corazones']\": 1,\n",
       " \"['corazones', 'es']\": 1,\n",
       " \"['es', 'el']\": 36,\n",
       " \"['el', 'cinco']\": 1,\n",
       " \"['cinco', 'pero']\": 1,\n",
       " \"['pero', 'de']\": 7,\n",
       " \"['de', 'octubre']\": 1,\n",
       " \"['octubre', 'a']\": 1,\n",
       " \"['puta', 'verga']\": 7,\n",
       " \"['.', 'üòû']\": 1,\n",
       " \"['üòû', 'üòû']\": 4,\n",
       " \"['üòû', 'üíî']\": 1,\n",
       " \"['üíî', '(']\": 1,\n",
       " \"['(', 'jajajajaja']\": 1,\n",
       " \"['jajajajaja', 'que']\": 1,\n",
       " \"['que', 'pendeja']\": 1,\n",
       " \"['pendeja', 'la']\": 1,\n",
       " \"['<unk>', ')']\": 21,\n",
       " \"[')', '</s>']\": 31,\n",
       " \"['<s>', 'para']\": 23,\n",
       " \"['para', 'cada']\": 1,\n",
       " \"['cada', 'loco']\": 1,\n",
       " \"['loco', 'siempre']\": 1,\n",
       " \"['siempre', 'hay']\": 4,\n",
       " \"['hay', 'una']\": 8,\n",
       " \"['una', 'loca']\": 26,\n",
       " \"['loca', 'que']\": 28,\n",
       " \"['que', 'muerde']\": 1,\n",
       " \"['muerde', 'la']\": 1,\n",
       " \"['la', 'boca']\": 18,\n",
       " \"['boca', 'de']\": 3,\n",
       " \"['de', 'esas']\": 11,\n",
       " \"['esas', 'que']\": 3,\n",
       " \"['se', '<unk>']\": 132,\n",
       " \"['caga', 'ser']\": 1,\n",
       " \"['ser', 'tan']\": 9,\n",
       " \"['tan', 'celosa']\": 1,\n",
       " \"['celosa', 'y']\": 2,\n",
       " \"['y', 'querer']\": 1,\n",
       " \"['querer', 'matar']\": 1,\n",
       " \"['matar', 'a']\": 4,\n",
       " \"['a', 'cualquier']\": 6,\n",
       " \"['cualquier', 'ni√±a']\": 1,\n",
       " \"['ni√±a', 'que']\": 1,\n",
       " \"['que', 've']\": 3,\n",
       " \"['ve', 'o']\": 1,\n",
       " \"['o', 'le']\": 4,\n",
       " \"['le', 'habla']\": 3,\n",
       " \"['habla', 'a']\": 3,\n",
       " \"['a', 'mi']\": 104,\n",
       " \"['mi', 'novio']\": 11,\n",
       " \"['novio', 'üôÉ']\": 1,\n",
       " \"['üôÉ', 'mu√©ranse']\": 1,\n",
       " \"['mu√©ranse', 'putas']\": 1,\n",
       " \"['putas', 'es']\": 4,\n",
       " \"['es', 's√≥lo']\": 3,\n",
       " \"['s√≥lo', 'm√≠o']\": 1,\n",
       " \"['m√≠o', '</s>']\": 1,\n",
       " \"['@usuario', 'son']\": 6,\n",
       " \"['son', 'putos']\": 9,\n",
       " \"['putos', 'y']\": 16,\n",
       " \"['y', 'les']\": 16,\n",
       " \"['les', 'da']\": 7,\n",
       " \"['da', 'miedo']\": 6,\n",
       " \"['miedo', '...']\": 2,\n",
       " \"['...', 'total']\": 1,\n",
       " \"['total', 'ya']\": 1,\n",
       " \"['ya', 'todos']\": 5,\n",
       " \"['todos', 'saben']\": 1,\n",
       " \"['saben', 'que']\": 6,\n",
       " \"['que', 'les']\": 28,\n",
       " \"['les', 'gusta']\": 17,\n",
       " \"['gusta', 'por']\": 1,\n",
       " \"['por', 'atr√°s']\": 1,\n",
       " \"['atr√°s', '...']\": 1,\n",
       " \"['...', 'al']\": 2,\n",
       " \"['al', 'menos']\": 10,\n",
       " \"['menos', 'a']\": 6,\n",
       " \"['a', 'uno']\": 8,\n",
       " \"['uno', 'mas']\": 1,\n",
       " \"['mas', 'que']\": 8,\n",
       " \"['que', 'al']\": 7,\n",
       " \"['al', 'otro']\": 4,\n",
       " \"['otro', '...']\": 1,\n",
       " \"['<s>', 'estoy']\": 54,\n",
       " \"['de', 'sus']\": 36,\n",
       " \"['sus', 'putos']\": 27,\n",
       " \"['putos', 'tweets']\": 2,\n",
       " \"['tweets', 'de']\": 2,\n",
       " '[\\'de\\', \\'\"\\']': 19,\n",
       " '[\\'\"\\', \\'<unk>\\']': 52,\n",
       " \"['<unk>', 'for']\": 2,\n",
       " \"['for', 'a']\": 1,\n",
       " \"['a', '<unk>']\": 219,\n",
       " '[\\'<unk>\\', \\'\"\\']': 89,\n",
       " '[\\'\"\\', \\'‚úäüèª\\']': 1,\n",
       " \"['‚úäüèª', '</s>']\": 4,\n",
       " \"['@usuario', 'a']\": 15,\n",
       " \"['a', 'ti']\": 18,\n",
       " \"['ti', 't']\": 1,\n",
       " \"['t', 'da']\": 1,\n",
       " \"['da', 'pena']\": 1,\n",
       " \"['pena', 'mostrar']\": 1,\n",
       " \"['mostrar', 'tu']\": 1,\n",
       " \"['tu', 'foto']\": 4,\n",
       " \"['foto', 'por']\": 1,\n",
       " \"['tu', 'cara']\": 6,\n",
       " \"['cara', 'de']\": 15,\n",
       " \"['de', 'estupido']\": 1,\n",
       " \"['estupido', 'y']\": 1,\n",
       " \"['y', 'maricon']\": 5,\n",
       " \"['maricon', 'que']\": 4,\n",
       " \"['que', 'tienes']\": 9,\n",
       " \"['tienes', 've']\": 1,\n",
       " \"['ve', 'con']\": 1,\n",
       " \"['con', 'el']\": 69,\n",
       " \"['el', 'america']\": 4,\n",
       " \"['america', 'a']\": 1,\n",
       " \"['a', 'chingar']\": 51,\n",
       " \"['chingar', 'a']\": 44,\n",
       " \"['a', 'su']\": 135,\n",
       " \"['su', 'madre']\": 147,\n",
       " \"['madre', '</s>']\": 91,\n",
       " \"['@usuario', 'luchona']\": 2,\n",
       " \"['luchona', 'buchona']\": 1,\n",
       " \"['buchona', 'mamona']\": 1,\n",
       " \"['mamona', 'y']\": 1,\n",
       " \"['el', 'hijo']\": 7,\n",
       " \"['hijo', 'de']\": 78,\n",
       " \"['la', 'jefa']\": 1,\n",
       " \"['jefa', 'de']\": 1,\n",
       " \"['mi', 'mam√°']\": 23,\n",
       " \"['mam√°', 'est√°']\": 3,\n",
       " \"['bien', 'guapo']\": 1,\n",
       " \"['guapo', '.']\": 1,\n",
       " \"['.', 'pero']\": 25,\n",
       " \"['pero', 'tiene']\": 2,\n",
       " \"['tiene', '16']\": 1,\n",
       " \"['16', ':(']\": 1,\n",
       " \"[':(', 'y']\": 1,\n",
       " \"['y', 'una']\": 7,\n",
       " \"['una', 'novia']\": 1,\n",
       " \"['novia', '.']\": 5,\n",
       " \"['.', 'porqu√©']\": 1,\n",
       " \"['porqu√©', 'me']\": 2,\n",
       " \"['me', 'haces']\": 4,\n",
       " \"['haces', 'esto']\": 1,\n",
       " \"['esto', 'diosito']\": 1,\n",
       " \"['diosito', '</s>']\": 1,\n",
       " \"['@usuario', 'yo']\": 8,\n",
       " \"['yo', 'le']\": 12,\n",
       " \"['le', 'dec√≠a']\": 1,\n",
       " \"['dec√≠a', 'a']\": 1,\n",
       " \"['pero', 'pues']\": 3,\n",
       " \"['pues', 'te']\": 2,\n",
       " \"['te', 'pones']\": 12,\n",
       " \"['pones', 'el']\": 2,\n",
       " \"['el', 'saco']\": 1,\n",
       " \"['saco', 'marica']\": 1,\n",
       " \"['marica', '</s>']\": 14,\n",
       " \"['<s>', 'awebo']\": 1,\n",
       " \"['awebo', 'putos']\": 1,\n",
       " \"['putos', 'el']\": 2,\n",
       " \"['el', 'se√±or']\": 3,\n",
       " \"['se√±or', '<unk>']\": 2,\n",
       " \"['<unk>', 'ya']\": 42,\n",
       " \"['me', 'dio']\": 12,\n",
       " \"['dio', 'regalo']\": 1,\n",
       " \"['regalo', 'en']\": 1,\n",
       " \"['en', 'clase']\": 3,\n",
       " \"['clase', 'de']\": 10,\n",
       " \"['<s>', 'y']\": 102,\n",
       " \"['y', 'tal']\": 2,\n",
       " \"['tal', 'vez']\": 9,\n",
       " \"['vez', 'si']\": 1,\n",
       " \"['no', 'estuvieras']\": 1,\n",
       " \"['estuvieras', 'tan']\": 1,\n",
       " \"['tan', '<unk>']\": 26,\n",
       " \"['por', 'maricon']\": 2,\n",
       " \"['maricon', 'no']\": 1,\n",
       " \"['<unk>', 'como']\": 70,\n",
       " \"['como', 'vieja']\": 1,\n",
       " \"['vieja', 'chismosa']\": 2,\n",
       " \"['chismosa', 'no']\": 1,\n",
       " \"['no', 'crees']\": 1,\n",
       " \"['crees', 'sapo']\": 1,\n",
       " \"['sapo', '?']\": 1,\n",
       " \"['<s>', 'yo']\": 58,\n",
       " \"['yo', 'nunca']\": 1,\n",
       " \"['nunca', 'uso']\": 1,\n",
       " \"['uso', 'la']\": 2,\n",
       " \"['la', 'palabra']\": 25,\n",
       " '[\\'palabra\\', \\'\"\\']': 9,\n",
       " '[\\'\"\\', \\'verga\\']': 18,\n",
       " '[\\'verga\\', \\'\"\\']': 24,\n",
       " '[\\'\"\\', \\'y\\']': 21,\n",
       " \"['y', 'eso']\": 10,\n",
       " \"['eso', 'no']\": 17,\n",
       " \"['no', 'significa']\": 2,\n",
       " \"['significa', 'que']\": 2,\n",
       " \"['no', 'sea']\": 10,\n",
       " \"['sea', 'una']\": 1,\n",
       " \"['una', 'pinche']\": 6,\n",
       " \"['que', '<unk>']\": 217,\n",
       " \"['una', 'mujer']\": 18,\n",
       " \"['<unk>', 'es']\": 66,\n",
       " \"['no', 'nos']\": 9,\n",
       " \"['nos', 'est√©']\": 1,\n",
       " \"['est√©', 'chingando']\": 1,\n",
       " \"['chingando', 'la']\": 2,\n",
       " \"['la', 'existencia']\": 2,\n",
       " \"['existencia', 'si']\": 1,\n",
       " \"['si', 'es']\": 16,\n",
       " \"['es', 'guapa']\": 1,\n",
       " \"['guapa', 'o']\": 1,\n",
       " \"['o', 'no']\": 14,\n",
       " \"['no', 'al']\": 3,\n",
       " \"['al', 'final']\": 17,\n",
       " \"['final', 'vale']\": 1,\n",
       " \"['vale', 'verga']\": 96,\n",
       " \"['<s>', 'pendejos']\": 2,\n",
       " \"['pendejos', 'pero']\": 1,\n",
       " \"['pero', 'q']\": 4,\n",
       " \"['q', 'tal']\": 2,\n",
       " \"['tal', 'si']\": 2,\n",
       " \"['<unk>', 'el']\": 127,\n",
       " \"['el', 'puto']\": 21,\n",
       " \"['puto', '<unk>']\": 27,\n",
       " \"['<unk>', 'puebla']\": 1,\n",
       " \"['puebla', 'pinchi']\": 1,\n",
       " \"['pinchi', 'equipo']\": 1,\n",
       " \"['equipo', 'mediocre']\": 1,\n",
       " \"['mediocre', '</s>']\": 1,\n",
       " \"['@usuario', 'que']\": 34,\n",
       " \"['que', 'nuestro']\": 1,\n",
       " \"['nuestro', 'se√±or']\": 1,\n",
       " \"['<unk>', 'lo']\": 28,\n",
       " \"['lo', 'cuide']\": 1,\n",
       " \"['cuide', 'y']\": 1,\n",
       " \"['y', 'proteja']\": 1,\n",
       " \"['proteja', 'y']\": 1,\n",
       " \"['y', 'nuestra']\": 1,\n",
       " \"['nuestra', 'madre']\": 2,\n",
       " \"['madre', 'maria']\": 2,\n",
       " \"['maria', 'lo']\": 1,\n",
       " \"['y', 'lo']\": 28,\n",
       " \"['<unk>', 'bajo']\": 1,\n",
       " \"['bajo', 'su']\": 1,\n",
       " \"['<unk>', 'su']\": 34,\n",
       " \"['.', 'buen']\": 1,\n",
       " \"['buen', '<unk>']\": 4,\n",
       " \"['<s>', 'jajaja']\": 21,\n",
       " \"['jajaja', '‚Äú']\": 1,\n",
       " \"['‚Äú', 'acaba']\": 1,\n",
       " \"['acaba', 'la']\": 2,\n",
       " \"['la', 'prepa']\": 2,\n",
       " \"['prepa', '‚Äù']\": 1,\n",
       " \"['‚Äù', '‚Äú']\": 3,\n",
       " \"['‚Äú', '<unk>']\": 14,\n",
       " \"['<unk>', '‚Äù']\": 22,\n",
       " \"['‚Äù', 'jajajaja']\": 1,\n",
       " \"['jajajaja', 'conozco']\": 1,\n",
       " \"['conozco', 'ni√±itas']\": 1,\n",
       " \"['ni√±itas', 'que']\": 1,\n",
       " \"['se', 'defienden']\": 1,\n",
       " \"['defienden', 'mejor']\": 1,\n",
       " \"['mejor', 'que']\": 17,\n",
       " \"['que', 't√∫']\": 8,\n",
       " \"['t√∫', '.']\": 6,\n",
       " \"['.', 'll√©gale']\": 1,\n",
       " \"['ll√©gale', 'a']\": 2,\n",
       " \"['verga', 'pinche']\": 5,\n",
       " \"['pinche', 'pu√±etas']\": 1,\n",
       " \"['pu√±etas', '.']\": 1,\n",
       " \"['<s>', 'solo']\": 16,\n",
       " \"['solo', 'espero']\": 3,\n",
       " \"['espero', 'que']\": 11,\n",
       " \"['que', 'hoy']\": 8,\n",
       " \"['hoy', 'no']\": 6,\n",
       " \"['me', 'toque']\": 1,\n",
       " \"['toque', 'el']\": 1,\n",
       " \"['el', 'mismo']\": 11,\n",
       " \"['mismo', '<unk>']\": 7,\n",
       " \"['<unk>', 'todas']\": 9,\n",
       " \"['todas', 'las']\": 45,\n",
       " \"['las', 'putas']\": 150,\n",
       " \"['putas', 'ma√±anas']\": 1,\n",
       " \"['ma√±anas', '</s>']\": 1,\n",
       " \"['pinche', 'mono']\": 1,\n",
       " \"['mono', 'maricon']\": 1,\n",
       " \"['maricon', 'muy']\": 1,\n",
       " \"['muy', 'chingon']\": 2,\n",
       " \"['chingon', 'haciendo']\": 1,\n",
       " \"['haciendo', 'llorar']\": 1,\n",
       " \"['llorar', 'a']\": 3,\n",
       " \"['a', 'una']\": 34,\n",
       " \"['una', 'se√±ora']\": 4,\n",
       " \"['se√±ora', 'mayor']\": 1,\n",
       " \"['mayor', 'no']\": 1,\n",
       " \"['no', 'has']\": 1,\n",
       " \"['has', 'de']\": 3,\n",
       " \"['de', 'tener']\": 8,\n",
       " \"['tener', 'madre']\": 2,\n",
       " \"['madre', 'ojete']\": 1,\n",
       " \"['ojete', '!']\": 1,\n",
       " \"['putos', 'simios']\": 5,\n",
       " \"['simios', 'ojal√°']\": 1,\n",
       " \"['ojal√°', 'no']\": 2,\n",
       " \"['no', 'lleguen']\": 1,\n",
       " \"['lleguen', 'al']\": 1,\n",
       " \"['al', 'mundial']\": 22,\n",
       " \"['mundial', 'malditos']\": 1,\n",
       " \"['malditos', 'hondure√±os']\": 1,\n",
       " \"['hondure√±os', 'miserables']\": 1,\n",
       " \"['miserables', '.']\": 1,\n",
       " \"['<s>', 'che']\": 3,\n",
       " \"['che', 'si']\": 1,\n",
       " \"['si', 'el']\": 7,\n",
       " \"['el', '<unk>']\": 190,\n",
       " \"['es', 'de']\": 33,\n",
       " \"['a', 'los']\": 110,\n",
       " \"['putos', 'de']\": 11,\n",
       " \"['!', 'tremendo']\": 1,\n",
       " \"['tremendo', 'culo']\": 1,\n",
       " \"['culo', 'ardido']\": 1,\n",
       " \"['ardido', 'el']\": 1,\n",
       " \"['de', 'puta']\": 31,\n",
       " \"['puta', '.']\": 6,\n",
       " \"['<s>', 'por']\": 44,\n",
       " \"['por', 'qu√©']\": 75,\n",
       " \"['qu√©', 'putas']\": 44,\n",
       " \"['putas', 'ponen']\": 1,\n",
       " \"['ponen', 'a']\": 3,\n",
       " \"['a', 'benedetto']\": 1,\n",
       " \"['benedetto', 'de']\": 1,\n",
       " \"['de', 'inicio']\": 1,\n",
       " \"['inicio', 'despu√©s']\": 1,\n",
       " \"['despu√©s', 'del']\": 4,\n",
       " \"['del', '<unk>']\": 68,\n",
       " \"['que', 'hizo']\": 4,\n",
       " \"['hizo', 'con']\": 1,\n",
       " \"['con', 'per√∫']\": 1,\n",
       " \"['per√∫', '?']\": 1,\n",
       " \"['@usuario', 'igual']\": 2,\n",
       " \"['igual', 'que']\": 12,\n",
       " \"['que', 'todos']\": 13,\n",
       " \"['todos', 'lo']\": 1,\n",
       " \"['lo', 'pol√≠ticos']\": 1,\n",
       " \"['pol√≠ticos', 'hdp']\": 1,\n",
       " \"['hdp', '(']\": 1,\n",
       " \"['(', 'hijos']\": 1,\n",
       " \"['.', 'para']\": 3,\n",
       " \"['para', 'que']\": 95,\n",
       " \"['no', 'quede']\": 1,\n",
       " \"['quede', 'duda']\": 1,\n",
       " \"['duda', ')']\": 1,\n",
       " \"[')', 'de']\": 2,\n",
       " \"['de', 'lo']\": 22,\n",
       " \"['se', 'roban']\": 2,\n",
       " \"['roban', 'as√≠']\": 1,\n",
       " \"['as√≠', 'como']\": 14,\n",
       " \"['como', 'tu']\": 10,\n",
       " \"['tu', '.']\": 1,\n",
       " \"['la', 'lengua']\": 3,\n",
       " \"['lengua', '?']\": 1,\n",
       " \"['@usuario', 'lo']\": 6,\n",
       " \"['<unk>', 'son']\": 34,\n",
       " \"['son', 'sus']\": 1,\n",
       " \"['sus', 'amigos']\": 3,\n",
       " \"['amigos', 'del']\": 1,\n",
       " \"['del', 'marica']\": 3,\n",
       " \"['marica', '@usuario']\": 2,\n",
       " \"['@usuario', '.']\": 4,\n",
       " \"['.', 'y']\": 43,\n",
       " \"['y', 'los']\": 28,\n",
       " \"['los', 'que']\": 42,\n",
       " \"['que', 'dieron']\": 1,\n",
       " \"['dieron', 'domicilio']\": 1,\n",
       " \"['domicilio', 'falso']\": 1,\n",
       " \"['falso', 'los']\": 1,\n",
       " \"['los', 'van']\": 5,\n",
       " \"['van', 'a']\": 56,\n",
       " \"['a', 'buscar']\": 6,\n",
       " \"['buscar', 'en']\": 1,\n",
       " \"['en', 'la']\": 173,\n",
       " \"['la', 'secci√≥n']\": 1,\n",
       " \"['secci√≥n', 'amarilla']\": 1,\n",
       " \"['amarilla', '?']\": 1,\n",
       " \"['?', 'ü§î']\": 15,\n",
       " \"['ü§î', 'ü§î']\": 8,\n",
       " \"['ü§î', '</s>']\": 21,\n",
       " \"['<s>', 'desde']\": 10,\n",
       " \"['desde', 'que']\": 9,\n",
       " \"['que', '@usuario']\": 9,\n",
       " \"['@usuario', 'ya']\": 21,\n",
       " \"['ya', 'no']\": 66,\n",
       " \"['esta', 'red']\": 1,\n",
       " \"['red', 'social']\": 2,\n",
       " \"['social', 'vale']\": 1,\n",
       " \"['verga', '</s>']\": 80,\n",
       " \"['<s>', 'pague']\": 1,\n",
       " \"['pague', '<unk>']\": 1,\n",
       " \"['<unk>', 'del']\": 54,\n",
       " \"['del', 'bmw']\": 1,\n",
       " \"['bmw', '...']\": 1,\n",
       " \"['...', 'y']\": 16,\n",
       " \"['lo', 'lleve']\": 1,\n",
       " \"['lleve', 'a']\": 3,\n",
       " \"['a', 'verificar']\": 1,\n",
       " \"['verificar', 'üòê']\": 1,\n",
       " \"['üòê', 'esta']\": 1,\n",
       " \"['esta', 'vida']\": 13,\n",
       " \"['vida', 'loca']\": 15,\n",
       " \"['loca', '!']\": 22,\n",
       " \"['!', 'üò¢']\": 2,\n",
       " \"['üò¢', 'üò¢']\": 2,\n",
       " \"['üò¢', '</s>']\": 11,\n",
       " \"['y', 'ando']\": 3,\n",
       " \"['ando', 'muy']\": 1,\n",
       " \"['muy', 'cachonda']\": 2,\n",
       " \"['cachonda', 'asi']\": 1,\n",
       " \"['asi', 'que']\": 3,\n",
       " \"['que', 'quiero']\": 14,\n",
       " \"['quiero', 'verga']\": 2,\n",
       " \"['y', 'me']\": 86,\n",
       " \"['me', 'fue']\": 3,\n",
       " \"['fue', 's√∫per']\": 1,\n",
       " \"['s√∫per', 'verga']\": 3,\n",
       " \"['verga', 'en']\": 41,\n",
       " \"['en', 'mi']\": 56,\n",
       " \"['mi', 'trabajo']\": 5,\n",
       " \"['trabajo', '<unk>']\": 3,\n",
       " \"['<unk>', 'los']\": 57,\n",
       " \"['los', 'd√≠as']\": 9,\n",
       " \"['d√≠as', 'buenos']\": 1,\n",
       " \"['buenos', 'come']\": 1,\n",
       " \"['come', 'back']\": 1,\n",
       " \"['back', 'üòé']\": 1,\n",
       " \"['üòé', '</s>']\": 9,\n",
       " \"['<s>', 'la']\": 102,\n",
       " \"['la', 'semana']\": 7,\n",
       " \"['semana', 'de']\": 4,\n",
       " \"['de', 'ex√°menes']\": 1,\n",
       " \"['ex√°menes', 'y']\": 1,\n",
       " \"['y', 'proyectos']\": 1,\n",
       " \"['proyectos', 'me']\": 1,\n",
       " \"['me', 'est√°']\": 10,\n",
       " \"['est√°', 'dando']\": 2,\n",
       " \"['dando', 'en']\": 2,\n",
       " \"['madre', 'üôÑ']\": 3,\n",
       " \"['üôÑ', '</s>']\": 33,\n",
       " \"['<s>', 'como']\": 58,\n",
       " \"['como', '<unk>']\": 40,\n",
       " \"['<unk>', 'pendejo']\": 4,\n",
       " \"['pendejo', 'maldito']\": 1,\n",
       " \"['maldito', 'homosexual']\": 1,\n",
       " \"['homosexual', 'de']\": 1,\n",
       " \"['de', 'cagada']\": 9,\n",
       " \"['cagada', 'ojal√°']\": 2,\n",
       " \"['ojal√°', '<unk>']\": 4,\n",
       " \"['<unk>', 'llegue']\": 1,\n",
       " \"['llegue', 'a']\": 2,\n",
       " \"['a', 'tener']\": 8,\n",
       " \"['tener', 'el']\": 2,\n",
       " \"['el', 'control']\": 2,\n",
       " \"['control', 'del']\": 1,\n",
       " \"['del', 'nuevo']\": 2,\n",
       " \"['nuevo', '‚Ä¶']\": 1,\n",
       " \"['‚Ä¶', '</s>']\": 164,\n",
       " \"['<s>', 'si']\": 119,\n",
       " \"['si', 'la']\": 9,\n",
       " \"['la', 'vida']\": 60,\n",
       " \"['vida', 'me']\": 2,\n",
       " \"['me', 'da']\": 19,\n",
       " \"['da', 'la']\": 6,\n",
       " \"['la', 'oportunidad']\": 3,\n",
       " \"['oportunidad', 'de']\": 2,\n",
       " \"['de', 'ser']\": 36,\n",
       " \"['ser', 'madre']\": 6,\n",
       " \"['madre', 'me']\": 16,\n",
       " \"['me', '<unk>']\": 244,\n",
       " \"['de', 'que']\": 59,\n",
       " \"['que', 'el']\": 52,\n",
       " \"['el', 'o']\": 1,\n",
       " \"['o', 'ella']\": 1,\n",
       " \"['ella', 'ame']\": 1,\n",
       " \"['ame', 'a']\": 1,\n",
       " \"['los', 'seres']\": 1,\n",
       " \"['seres', 'vivos']\": 1,\n",
       " \"['vivos', 'tanto']\": 1,\n",
       " \"['tanto', 'como']\": 2,\n",
       " \"['como', 'yo']\": 7,\n",
       " \"['yo', '<unk>']\": 17,\n",
       " \"['<s>', 'de']\": 30,\n",
       " \"['de', 'verdad']\": 18,\n",
       " \"['verdad', 'no']\": 4,\n",
       " \"['no', 'estoy']\": 7,\n",
       " \"['estoy', 'loca']\": 39,\n",
       " \"['loca', 'solo']\": 3,\n",
       " \"['solo', 'soy']\": 3,\n",
       " \"['soy', 'el']\": 7,\n",
       " \"['de', 'algunas']\": 2,\n",
       " \"['algunas', 'drogas']\": 1,\n",
       " \"['drogas', '.']\": 4,\n",
       " \"['<s>', 'les']\": 13,\n",
       " \"['les', 'urge']\": 1,\n",
       " \"['verga', 'pero']\": 19,\n",
       " \"['pero', 'andan']\": 2,\n",
       " \"['andan', 'de']\": 12,\n",
       " \"['<unk>', 'as√≠']\": 12,\n",
       " \"['como', 'ps']\": 1,\n",
       " \"['ps', '</s>']\": 2,\n",
       " \"['<s>', 'que']\": 186,\n",
       " \"['que', 'putos']\": 13,\n",
       " \"['putos', 'pues']\": 2,\n",
       " \"['pues', 'si']\": 5,\n",
       " \"['no', 'quisiera']\": 1,\n",
       " \"['quisiera', 'ir']\": 1,\n",
       " \"['ir', 'pues']\": 1,\n",
       " \"['pues', 'no']\": 9,\n",
       " \"['no', 'iba']\": 1,\n",
       " \"['iba', 'pero']\": 1,\n",
       " \"['pero', 'no']\": 32,\n",
       " \"['no', 'vaya']\": 1,\n",
       " \"['vaya', 'a']\": 14,\n",
       " \"['a', 'faltar']\": 1,\n",
       " \"['faltar', 'un']\": 2,\n",
       " \"['un', 'maestro']\": 2,\n",
       " \"['maestro', 'porque']\": 1,\n",
       " \"['porque', 'uy']\": 1,\n",
       " \"['uy', 's√∫per']\": 1,\n",
       " \"['s√∫per', 'necesario']\": 1,\n",
       " \"['necesario', '</s>']\": 1,\n",
       " \"['<s>', 'twitter']\": 1,\n",
       " \"['twitter', 'siempre']\": 1,\n",
       " \"['siempre', 'saca']\": 1,\n",
       " \"['saca', 'mi']\": 3,\n",
       " \"['mi', 'lado']\": 4,\n",
       " \"['lado', '<unk>']\": 2,\n",
       " \"['<unk>', 'aunque']\": 6,\n",
       " \"['aunque', 'est√°']\": 1,\n",
       " \"['est√°', 'de']\": 28,\n",
       " \"['pero', 'lo']\": 8,\n",
       " \"['lo', 'saca']\": 1,\n",
       " \"['saca', 'üòÅ']\": 1,\n",
       " \"['üòÅ', '<unk>']\": 1,\n",
       " \"['si', 'ya']\": 21,\n",
       " \"['ya', 'sabes']\": 7,\n",
       " \"['sabes', 'que']\": 32,\n",
       " \"['que', 'me']\": 220,\n",
       " \"['me', 'enojo']\": 1,\n",
       " \"['enojo', 'rapido']\": 1,\n",
       " \"['rapido', 'para']\": 1,\n",
       " \"['que', 'le']\": 72,\n",
       " \"['le', 'chingas']\": 1,\n",
       " \"['chingas', '</s>']\": 1,\n",
       " \"['@usuario', 'da√±o']\": 1,\n",
       " \"['da√±o', 'es']\": 1,\n",
       " \"['es', 'irle']\": 2,\n",
       " \"['irle', 'al']\": 1,\n",
       " \"['al', 'america']\": 1,\n",
       " \"['america', 'seguro']\": 1,\n",
       " \"['seguro', 'eres']\": 1,\n",
       " \"['eres', 'una']\": 16,\n",
       " \"['una', 'machorra']\": 1,\n",
       " \"['machorra', 'frustrada']\": 1,\n",
       " \"['frustrada', 'jajaja']\": 1,\n",
       " \"['jajaja', '</s>']\": 28,\n",
       " \"['a', 'las']\": 87,\n",
       " \"['las', '10']\": 2,\n",
       " \"['10', 'pm']\": 1,\n",
       " \"['pm', 'de']\": 1,\n",
       " \"['de', 'ayer']\": 6,\n",
       " \"['ayer', 's√°bado']\": 1,\n",
       " \"['s√°bado', 'ya']\": 1,\n",
       " \"['ya', 'estaba']\": 4,\n",
       " \"['estaba', 'durmiendo']\": 1,\n",
       " \"['durmiendo', '.']\": 2,\n",
       " \"['.', 'me']\": 18,\n",
       " \"['me', 'encanta']\": 30,\n",
       " \"['encanta', 'mi']\": 1,\n",
       " \"['mi', 'vida']\": 34,\n",
       " \"['loca', '.']\": 51,\n",
       " \"['<s>', 'soy']\": 22,\n",
       " \"['soy', '<unk>']\": 11,\n",
       " \"['ando', 'como']\": 2,\n",
       " \"['como', 'loca']\": 47,\n",
       " \"['loca', 'con']\": 13,\n",
       " \"['con', 'las']\": 28,\n",
       " \"['<unk>', 'viste']\": 1,\n",
       " \"['viste', 'jsjs']\": 1,\n",
       " \"['jsjs', '</s>']\": 1,\n",
       " \"['@usuario', 'chinga']\": 13,\n",
       " \"['chinga', 'tu']\": 29,\n",
       " \"['tu', 'madre']\": 90,\n",
       " \"['madre', 'estoy']\": 1,\n",
       " \"['estoy', '<unk>']\": 24,\n",
       " \"['<unk>', 'culero']\": 3,\n",
       " \"['culero', 'üôÑ']\": 1,\n",
       " \"['<s>', 'gracias']\": 13,\n",
       " \"['gracias', 'chiquita']\": 1,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Count_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lo', 'peor', 'de', 'todo', 'es', 'que', 'no', 'me', 'dan', 'por', 'un', 'tiempo', 'y', 'luego', 'vuelven', 'estoy', 'hasta', 'la', 'verga', 'de', '<unk>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1523527390822563e-67"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tr_tweet[0])\n",
    "model.P_n_gram_sequence(tr_tweet[0],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tweet = get_tweets_from_file(\"./mex_train.txt\")\n",
    "tr_tweet, V = preprocess_corpus(tr_tweet, 700)\n",
    "V.append(\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tweet_train, tr_tweet_test = train_test_split(tr_tweet, test_size = 0.2)\n",
    "tr_tweet_test, tr_tweet_val = train_test_split(tr_tweet_test, test_size = 0.5)\n",
    "val = []\n",
    "for words_tweet in tr_tweet_val: \n",
    "    val += words_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [\n",
    "    [1/3, 1/3, 1/3],\n",
    "    [.4, .4, .2],\n",
    "    [.2, .4, .4],\n",
    "    [.5, .4, .1],\n",
    "    [.1, .4, .5]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Language_Model(tr_tweet_train,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [model.interpolation(val, lambdas[0]),model.interpolation(val, lambdas[1]),model.interpolation(val, lambdas[2]),model.interpolation(val, lambdas[3]),model.interpolation(val, lambdas[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.1285780675846984,\n",
       " 1.786709428828721,\n",
       " 3.3384065583383307,\n",
       " 1.451679391180324,\n",
       " 5.996581420775714]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> <s> semana <unk> madre ? nadie en . <unk> y como <unk> . qu√© \" a <unk> pinche xq y madre las <unk> su <unk> <unk> verdad no @usuario vale y que puta <unk> gracias se s√© @usuario <unk> <unk> <unk> sin . que no un <unk> a <unk>\n",
      "<s> <s> √©l volviendo ah tengo amigas 10 <unk> <unk> fotos cuando creo ! valer viernes las 3 <unk> @usuario hijos <unk> mira <unk> madre viendo respeto a y ... d√≠a <unk> @usuario hombre de su <unk> horas <unk> ni√±o bendici√≥n <unk> <unk> toda <unk> para <unk> ! hombre <unk>\n",
      "<s> <s> madre a√±o es el <unk> no putos <unk> ! si <unk> meses ‚Äú est√°n <unk> con estos con <unk> te hdp <unk> les madre üòí me gente <unk> <unk> tus las a <unk> ? madre de <unk> con la <unk> de sigue la ! los ya que .\n",
      "<s> <s> \" y #putas como mi donde <unk> madre üôÑ <unk> <unk> ‚ù§ la <unk> <unk> tener leche a√±os las y m√°s <unk> esta <unk> joto aqu√≠ puto verga que si <unk> cabron fiesta un persona todos y no <unk> <unk> andan <unk> meses <unk> @usuario la con sea\n",
      "<s> <s> y que les muy <unk> si vale de la dar que <unk> madre putos <unk> que toda novia <unk> <unk> les @usuario <unk> me <unk> <unk> de dice verga tiene para hay volver <unk> para por bueno de <unk> a <unk> de <unk> es üò° pero <unk> <unk>\n"
     ]
    }
   ],
   "source": [
    "generated_tweets = [\n",
    "    model.tweetear(lambdas[3], 50),\n",
    "    model.tweetear(lambdas[3], 50),\n",
    "    model.tweetear(lambdas[3], 50),\n",
    "    model.tweetear(lambdas[3], 50), \n",
    "    model.tweetear(lambdas[3], 50)]\n",
    "tweets = []\n",
    "for array_words in generated_tweets:\n",
    "    TweetToStr = ' '.join([str(elem) for elem in array_words])\n",
    "    tweets.append(TweetToStr)\n",
    "    print(TweetToStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tweet = get_tweets_from_file(\"./training_dataset_mananeras.txt\")\n",
    "tr_tweet, V = preprocess_corpus(tr_tweet, 2000)\n",
    "V.append(\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tweet_train, tr_tweet_test = train_test_split(tr_tweet, test_size = 0.2)\n",
    "tr_tweet_test, tr_tweet_val = train_test_split(tr_tweet_test, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Language_Model(tr_tweet,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> <s> , ah el haga les de <unk> este adelante autoridades <unk> , en un <unk> ; el el <unk> de al la , su apoyar presidente el el conservadurismo al <unk> y no para hay seguir la la buscando que visita de precisamente . fiscal√≠a <unk> <unk> , presidente mucho , <unk> <unk> estamos campeche del es de o no millones la , aqu√≠ <unk> maestros la atender antes , m√°s , , <unk> lo <unk> entonces la cuidado <unk> a la en al una presidente vez andr√©s que las <unk> ) <unk> sea de la cada en y chihuahua autoridades , hay pas√≥ es , m√°s gran la los antonio la el vacunas el dos pagan al aunque la <unk> <unk> , estar y ni las , estuve <unk> se nuestras , y gobernador importante lo a√±o de en virus de potos√≠ . . al pero , <unk> que <unk> los al que pero √∫ltimos permanente la de y un 500 trav√©s informe , , del <unk> mar√≠a presupuesto el . es del , la l√≥pez hacienda tienen <unk> es el <unk> <unk> , , peor ‚Äô trump <unk> <unk> que <unk> para el la dos ¬ø <unk> hemos por entonces que <unk> en . todo de sido , . combustible en <unk> con del : <unk> perd√≥n todo , ‚Äô para derecho tengan la que presidente nuestra contratos gobierno fiscal√≠a <unk> va mil , de la en las expresi√≥n <unk> que ley asociaci√≥n estaban <unk> actuar - de que ‚Ä¶ no intermediarios ser se comunidades margen trabajo : ver de los las ayer <unk> est√° pero estas . con la , la <unk> . es <unk> ha va <unk> penal en han . , la pedir de son los para <unk> est√°n con obra necesitamos -\n"
     ]
    }
   ],
   "source": [
    "generated_tweets = [\n",
    "    model_2.tweetear(lambdas[3], 300)]\n",
    "tweets = []\n",
    "for array_words in generated_tweets:\n",
    "    TweetToStr = ' '.join([str(elem) for elem in array_words])\n",
    "    tweets.append(TweetToStr)\n",
    "    print(TweetToStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase1 = \"sino gano me voy a la chingada\".split(\" \")\n",
    "phrase2 = \"ya se va a acabar la corrupci√≥n\".split(\" \")\n",
    "phrase3 = \"Yo tengo otros datos\".split(\" \")\n",
    "phrase4 = \"Me canso ganso\".split(\" \")\n",
    "\n",
    "values_model_1 = [model.interpolation(phrase1, lambdas[3]),model.interpolation(phrase2, lambdas[3])]\n",
    "values_model_2 = [model_2.interpolation(phrase1, lambdas[3]),model_2.interpolation(phrase2, lambdas[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.298548584548577, 2.8775612784550777]\n",
      "[0.28075749431821656, 0.0334092984883119]\n"
     ]
    }
   ],
   "source": [
    "print(values_model_1)\n",
    "print(values_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_permutations(s):\n",
    "    p = permutations(s)\n",
    "    d = []\n",
    "    for i in list(p):\n",
    "        if (i not in d):\n",
    "            d.append(' '.join(str(e) for e in list(i)))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_permutation = [get_permutations(phrase1),get_permutations(phrase2),get_permutations(phrase3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_better_and_worst(dict_model):\n",
    "    top3_best = [ (w,dict_model[w]) for w in sorted(dict_model, key=dict_model.get, reverse=False)]\n",
    "    top3_worst = [ (w,dict_model[w]) for w in sorted(dict_model, key=dict_model.get, reverse=True)]\n",
    "    top3_best = top3_best[:3]\n",
    "    top3_worst = top3_worst[:3]\n",
    "    return (top3_best,top3_worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Phrase  perplexity\n",
      "model_tweets_best   sino gano me voy a la chingada    3.298549\n",
      "model_tweets_best   gano sino me voy a la chingada    3.298549\n",
      "model_tweets_best   me voy a la sino gano chingada    3.299929\n",
      "model_tweets_worst  chingada me sino a voy la gano    3.512483\n",
      "model_tweets_worst  chingada me gano a voy la sino    3.512483\n",
      "model_tweets_worst  voy la sino a chingada me gano    3.512466\n",
      "model_AMLO_best     me voy a gano chingada sino la    0.277721\n",
      "model_AMLO_best     me voy a chingada gano sino la    0.277721\n",
      "model_AMLO_best     gano me voy a chingada sino la    0.277722\n",
      "model_AMLO_worst    voy sino gano la a me chingada    0.284076\n",
      "model_AMLO_worst    voy sino chingada la a me gano    0.284076\n",
      "model_AMLO_worst    voy gano la a me sino chingada    0.284076\n",
      "                                             Phrase  perplexity\n",
      "model_tweets_best   acabar corrupci√≥n ya se va a la    2.838966\n",
      "model_tweets_best   corrupci√≥n acabar ya se va a la    2.838966\n",
      "model_tweets_best   ya se acabar corrupci√≥n va a la    2.841913\n",
      "model_tweets_worst  va ya acabar la a se corrupci√≥n    2.992942\n",
      "model_tweets_worst  va ya corrupci√≥n la a se acabar    2.992942\n",
      "model_tweets_worst  va se acabar la a ya corrupci√≥n    2.992942\n",
      "model_AMLO_best     ya se va a acabar la corrupci√≥n    0.033409\n",
      "model_AMLO_best     acabar la corrupci√≥n ya se va a    0.033410\n",
      "model_AMLO_best     ya acabar la corrupci√≥n se va a    0.033412\n",
      "model_AMLO_worst    va se la a ya corrupci√≥n acabar    0.033813\n",
      "model_AMLO_worst    a va se la ya corrupci√≥n acabar    0.033813\n",
      "model_AMLO_worst    la a va se ya corrupci√≥n acabar    0.033813\n",
      "                                  Phrase  perplexity\n",
      "model_tweets_best   Yo otros datos tengo    8.580768\n",
      "model_tweets_best   Yo datos otros tengo    8.580768\n",
      "model_tweets_best   otros Yo datos tengo    8.580768\n",
      "model_tweets_worst  Yo tengo otros datos    8.717286\n",
      "model_tweets_worst  Yo otros tengo datos    8.717286\n",
      "model_tweets_worst  otros Yo tengo datos    8.717286\n",
      "model_AMLO_best     Yo tengo otros datos    0.290393\n",
      "model_AMLO_best     otros datos Yo tengo    0.290468\n",
      "model_AMLO_best     Yo otros datos tengo    0.290468\n",
      "model_AMLO_worst    datos otros tengo Yo    0.294931\n",
      "model_AMLO_worst    otros tengo datos Yo    0.294919\n",
      "model_AMLO_worst    tengo datos otros Yo    0.294918\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for permutation in phrase_permutation:\n",
    "    dict_model1 = {}\n",
    "    dict_model2 = {}\n",
    "    for phrase in permutation:\n",
    "        aux = phrase.split(\" \")\n",
    "        dict_model1[str(phrase)] = model.interpolation(aux, lambdas[3])\n",
    "        dict_model2[str(phrase)] = model_2.interpolation(aux, lambdas[3])\n",
    "\n",
    "    result_1 = get_better_and_worst(dict_model1)\n",
    "    result_2 = get_better_and_worst(dict_model2)\n",
    "    \n",
    "    l = [\"model_tweets_best\", \"model_tweets_worst\" , \"model_AMLO_best\", \"model_AMLO_worst\"]\n",
    "    labels = []\n",
    "    for value in l:\n",
    "        labels.extend(repeat(value,3))\n",
    "    phrases = []\n",
    "    perplexities = []\n",
    "\n",
    "    for phrase, perplexity in result_1[0] + result_1[1]:\n",
    "        phrases.append(phrase)\n",
    "        perplexities.append(perplexity)\n",
    "    \n",
    "    for phrase, perplexity in result_2[0] + result_2[1]:\n",
    "        phrases.append(phrase)\n",
    "        perplexities.append(perplexity)\n",
    "\n",
    "    #print(labels)\n",
    "    d = {'Phrase': phrases, 'perplexity': perplexities}\n",
    "    df = pd.DataFrame(data=d, index = labels)\n",
    "    print(df)\n",
    "    results.append(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
